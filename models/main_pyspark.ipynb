{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0b93311c-8c62-4668-bb72-a16edbc70cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocessing import pre_phonetic_encoding, pre_string_clean#, pre_tokenize, pre_sort_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a54fafaa-62c7-4930-9ea3-111b748001af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType, DateType, BinaryType, BooleanType, ByteType, MapType\n",
    "from pyspark.sql.functions import expr, lit\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc01e6cf-933b-47e9-a979-0cf425d923fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-07 11:03:50 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('Entity-Resolution').getOrCreate()\n",
    "sparkContext=spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f830b-f3d3-4c24-ab72-1e8e17281b36",
   "metadata": {},
   "source": [
    "#### For now, we assume that entities have been deduplicated already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea90d077-ce54-470c-ae81-964450c53df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[person_id: string, service_date: string, first_name: string, middle_name: string, last_name: string, dob: string, ssn: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = spark.read.csv(\"../simulated_data/dataset_1.csv\", header=True,\n",
    "    mode=\"DROPMALFORMED\",)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fc0306-da4d-440a-b910-6015fdcd6a8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[person_id: string, service_date: string, first_name: string, middle_name: string, last_name: string, dob: string, ssn: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = spark.read.csv(\"../simulated_data/dataset_2.csv\", header=True,\n",
    "    mode=\"DROPMALFORMED\",)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde97315-bcc4-4696-a0cc-44700f269064",
   "metadata": {},
   "source": [
    "## Preprocessing steps \n",
    "Assign each preprocessing step to a udf, then apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a76caba-1630-405f-8b5e-b90a86e0491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UDFs\n",
    "udf_pre_phonetic_encoding = udf(pre_phonetic_encoding, StringType()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "670f7e85-d106-47f5-a067-1eacdf1e3ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(person_id='1000', service_date='2020-09-02', first_name='christiano', middle_name='Allen', last_name='Marquez', dob='1967-05-29', ssn='119-77-5956', phonetic_name='XRSXN', phonetic_last_name='MRKS')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.withColumn(\"phonetic_name\", udf_pre_phonetic_encoding(\"first_name\"))\n",
    "df1 = df1.withColumn(\"phonetic_last_name\", udf_pre_phonetic_encoding(\"last_name\"))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20135fbd-20f1-4acf-8af1-78884dcaef6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(person_id='1000', service_date='2020-09-02', first_name='chris', middle_name='Allen', last_name='Marquez', dob='1967-05-29', ssn='119-77-5956', phonetic_name='XRS', phonetic_last_name='MRKS')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.withColumn(\"phonetic_name\", udf_pre_phonetic_encoding(\"first_name\"))\n",
    "df2 = df2.withColumn(\"phonetic_last_name\", udf_pre_phonetic_encoding(\"last_name\"))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6ed5e3-98ec-46c9-bde7-ddb05a808e3a",
   "metadata": {},
   "source": [
    "## Now to the hashing and linking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb82960-8b75-47b1-be9b-221fd364d34c",
   "metadata": {},
   "source": [
    "### Bloom filter on name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "30604f4c-a0b2-41cd-b6de-6efcf5196e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitarray\n",
    "import mmh3\n",
    "def bloom_hash(item, size, hash_count):\n",
    "    bit_array = bitarray.bitarray(size)\n",
    "    bit_array.setall(0)\n",
    "    for ii in range(hash_count):\n",
    "        index = mmh3.hash(item, ii) % size\n",
    "        bit_array[index] = 1\n",
    "    return bytes(bit_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9fc12729-ef4d-4bb8-b9e4-3594fab5b4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00@\\xa0\\x00'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom_hash(\"bahg\", 30, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7183cd94-8f31-4ab5-bc11-a679e0eea36d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringType"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitarray_type = StringType()#ArrayType(ByteType())\n",
    "bitarray_type.needConversion()\n",
    "bitarray_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1da8f407-f047-415c-ab84-294d92685968",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_bloom = udf(bloom_hash, bitarray_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1ca1cb-2d51-42b7-8376-37f21a0ea866",
   "metadata": {},
   "source": [
    "#### Steps\n",
    "For each bloom filter function:\n",
    "* Map: \"Hash\" entities according to algorithm\n",
    "* Map: Assign block, sum 1s in hash\n",
    "* Join: inner join to compute pairwise distances (Dice coefficient)\n",
    "* Groupby: find min distance\n",
    "* Filter for entities that meet threshold - these are the potential candidates\n",
    "\n",
    "For all entity dataframes with associated candidates\n",
    "* join by entity\n",
    "* Pick candidate (how tho? :) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64cac4-6a32-46e3-8f0d-62a05b138c68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "98c4b5cf-58e0-4467-9624-783f1ab51060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(person_id='1000', service_date='2020-09-02', first_name='christiano', middle_name='Allen', last_name='Marquez', dob='1967-05-29', ssn='119-77-5956', phonetic_name='XRSXN', phonetic_last_name='MRKS', bloom_1='[B@599154e2', bloom_1_binary=bytearray(b'[B@599154e2'))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df1.withColumn(\"bloom_1\", udf_bloom(\"phonetic_name\", lit(100), lit(5)))\n",
    "df1 = df1.withColumn(\"bloom_1_binary\", df1.bloom_1.cast(BinaryType()))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "62911250-6989-49d2-b7e9-1d9b837636b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_block(bits, n_digits = 3):\n",
    "    if len(bits) < 3:\n",
    "        raise ValueError(\"bloom filter bytearray should be longer than 2 digits\")\n",
    "    else:\n",
    "        digits = [int(x) for x in list(bits[0:4])]\n",
    "        if digits[0] == 0:\n",
    "            return 3 + sum(digits)\n",
    "        else:\n",
    "            return sum(digits)\n",
    "        \n",
    "def sum_digits(bits):\n",
    "    digits = [int(x) for x in list(bits)]\n",
    "    return sum(digits)\n",
    "\n",
    "def dice_coeff(bits1, bits2):\n",
    "    bits = list(zip(bits1, bits2))\n",
    "    commons = sum([x[0] == x[1] for x in bits])\n",
    "    return (2 * commons) / (sum_digits(bits1) + sum_digits(bits2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6c238871-e1fd-4d03-b79b-d3d5a9b28362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(assign_block('111'))\n",
    "print(assign_block('000'))\n",
    "print(assign_block('001'))\n",
    "print(assign_block('011'))\n",
    "print(assign_block('101'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ea166b25-763e-448c-9e37-3921bd5070d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_coeff(\"1001\", \"1111\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6175431-b86e-4aee-a076-ad01e2152248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1c4ce9-ba2b-4fae-8680-be5c5246ee04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d45d162-6350-434b-9275-c72966f24b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b70e551c-14a6-4d57-917f-0bde960e8f09",
   "metadata": {},
   "source": [
    "### Composite Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95174815-fabf-4a5d-b386-209a92d9ab21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57978abe-1209-4949-a492-db0c2b26d32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567e909-46c2-44bb-93d5-c0eb091b603b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196feee-ef69-40c4-9d89-7cac37245817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd8f9616-e4b1-475c-884c-f282c5fd33a1",
   "metadata": {},
   "source": [
    "self join code for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f3ff381-278c-4853-ae87-34b008a19ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sparkContext.parallelize(\n",
    "    [(\"a\", 1,2),(\"a\",1,4),(\"b\",5,6),(\"b\",10,2),(\"c\",1,1)]\n",
    "  ).toDF()#\"id\",\"x\",\"y\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c4aacb4-1e62-4529-bca6-f756aaa8dda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_1='a', _2=1, _3=2),\n",
       " Row(_1='a', _2=1, _3=4),\n",
       " Row(_1='b', _2=5, _3=6),\n",
       " Row(_1='b', _2=10, _3=2),\n",
       " Row(_1='c', _2=1, _3=1)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8db6ea9-0b64-4a62-baa2-0b32a7c4e41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(_1='c', dx=0, dy=0),\n",
       " Row(_1='b', dx=0, dy=0),\n",
       " Row(_1='b', dx=0, dy=0),\n",
       " Row(_1='b', dx=0, dy=0),\n",
       " Row(_1='b', dx=0, dy=0),\n",
       " Row(_1='a', dx=0, dy=0),\n",
       " Row(_1='a', dx=0, dy=0),\n",
       " Row(_1='a', dx=0, dy=0),\n",
       " Row(_1='a', dx=0, dy=0)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = df.alias(\"left\")\n",
    "right = df.alias(\"right\")\n",
    "\n",
    "left.join(right,\"_1\").select(df._1,\n",
    "      (left._2-right._2).alias(\"dx\"),\n",
    "      (left._3-right._3).alias(\"dy\")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8ca01f-8c8c-4f55-94bc-aa27571c9f80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f99505-859d-408a-9a60-3c006c9430d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
