{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b93311c-8c62-4668-bb72-a16edbc70cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from hashing.preprocessing import pre_phonetic_encoding, pre_string_clean#, pre_tokenize, pre_sort_names\n",
    "from hashing.bloom import bloom_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a54fafaa-62c7-4930-9ea3-111b748001af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, ArrayType, IntegerType, DateType, BinaryType, BooleanType, ByteType, MapType\n",
    "from pyspark.sql.functions import expr, lit\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import functions as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0413d4b0-e5d4-43e7-9bc3-a702d4bac10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Entity-Resolution-Hasing').getOrCreate()\n",
    "sparkContext=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0618c8d-93ae-472f-bc2d-5e606de3f0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"../simulated_data/dataset_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea90d077-ce54-470c-ae81-964450c53df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(dataset, header=True,\n",
    "    mode=\"DROPMALFORMED\",)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1388db-ffda-4cd7-a283-10ae69494193",
   "metadata": {},
   "source": [
    "## Parameter Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e75a732-c4ba-4e79-bd3c-5460dc411c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, import set of unique identifiers and fuzzy identifiers that are agreed upon in the matching\n",
    "f = open(\"param_config.json\")\n",
    "fields = json.load(f)\n",
    "# fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde97315-bcc4-4696-a0cc-44700f269064",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing steps \n",
    "Assign each preprocessing step to a udf, then apply to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e010c11-364a-4e54-8587-8d2753728766",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UDFs\n",
    "udf_pre_phonetic_encoding = udf(pre_phonetic_encoding, StringType()) \n",
    "## TO DO: add all udfs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c17652a-19fa-476e-99b9-e4b67d283b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess implements all preprocessing steps for a column\n",
    "def preprocess(field_configs, data):\n",
    "    data = data.withColumn(field_configs['field_name'], data[field_configs['field_origin']])\n",
    "    for step in field_configs['preprocess_steps']:\n",
    "        if step == 'drop_chars':\n",
    "            data = data#.withColumn(field_configs['field']+'_'+step, #udfXYZ)\n",
    "        elif step == 'sort':\n",
    "            data = data\n",
    "        elif step == 'phonetic':\n",
    "            data = data.withColumn(field_configs['field_name'], udf_pre_phonetic_encoding(field_configs['field_name']))\n",
    "        else:\n",
    "            raise ValueError(\"Unknown preprocessing step\")\n",
    "    return data\n",
    "            \n",
    "def preprocess_all(configs, data):\n",
    "    for config in configs['fields']:\n",
    "        data = preprocess(config, data)\n",
    "    return data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a76caba-1630-405f-8b5e-b90a86e0491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_proc = preprocess_all(fields, df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470b249-471b-4518-a93f-6bcd63175a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b6ed5e3-98ec-46c9-bde7-ddb05a808e3a",
   "metadata": {},
   "source": [
    "## Now to the hashing and linking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb82960-8b75-47b1-be9b-221fd364d34c",
   "metadata": {},
   "source": [
    "### Bloom filter on name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30604f4c-a0b2-41cd-b6de-6efcf5196e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringType"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitarray_type = StringType()#ArrayType(ByteType())\n",
    "bitarray_type.needConversion()\n",
    "bitarray_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68fdc03c-9e14-4ade-8fb0-1fb6149e08a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_bloom = udf(bloom_hash, bitarray_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a99fda9-b410-4590-85aa-49d1ad71cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bloom_filters(configs, data, key = '_bloomhash'):\n",
    "    for field in configs['fields']:\n",
    "        data = data.withColumn(field['field_name'] + key, udf_bloom(field['field_name'], lit(100), lit(5)))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f322d1-3272-4b12-a06e-c74fd9b4f425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cf91eb39-d48e-4e07-b2e6-2330c9e515a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '_bloomhash'\n",
    "data_proc = bloom_filters(fields, data_proc, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60a982fa-52ad-4db0-8516-d6d4307aff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashed_output_bloomhash_1650943904\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "timestamp = str(int(dt.datetime.timestamp(dt.datetime.utcnow())))\n",
    "output = \"hashed_output\" + key + \"_\" + timestamp\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6cc0e1f6-02f5-4e3b-bc7d-507b1168e868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_proc.write.option(\"header\", True).csv(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd2190ea-1bab-4d55-aaeb-a483136526ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly from dictionary\n",
    "f = timestamp + \"_param_config.json\"\n",
    "with open(f, 'w') as outfile:\n",
    "    json.dump(fields, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1da8f407-f047-415c-ab84-294d92685968",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe0991f-ddda-47e2-8a31-db18b8e68cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
